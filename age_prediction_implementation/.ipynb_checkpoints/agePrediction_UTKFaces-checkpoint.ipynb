{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4268009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np              # za operacije nad arrayevima\n",
    "import matplotlib.pyplot as plt # za prikaz slika\n",
    "from matplotlib.patches import Rectangle\n",
    "import os                       # za iteriranje po direktorijima\n",
    "import cv2                      # za operacije nad slikama \n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "#!pip install mtcnn\n",
    "from mtcnn import MTCNN\n",
    "import time\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import LayerNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f84066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb-wiki set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35f2677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ucitaj dir \n",
    "#wikiDir = Path(\"/Users/ninaanic/Tehnicke/6_semestar/ZavRad/main/datasets/wiki_crop\")\n",
    "#filepaths_wiki = pd.Series(list(wikiDir.glob(r'**/*.jpg')), name = 'Filepath').astype(str)\n",
    "#\n",
    "## stvori matricu gdje je jedan stupac naziv slike a 2. broj godina u float-u\n",
    "#ages = []\n",
    "#for img in filepaths_wiki:\n",
    "#    filename = os.path.split(img)[1]\n",
    "#    if (filename == \".DS_Store\"):\n",
    "#        continue\n",
    "#    \n",
    "#    try:\n",
    "#        broj_god = int(filename.split('.')[0].split('_')[2]) - int(filename.split('_')[1].split('-')[0])\n",
    "#        ages.append(np.array(broj_god))\n",
    "#        \n",
    "#    except Exception as e:\n",
    "#        pass\n",
    "#\n",
    "#ages = pd.Series(np.array(ages, dtype = np.float64) , name = 'Age')  # One-dimensional ndarray with axis labels ('Age')\n",
    "#images_wiki = pd.concat([filepaths_wiki, ages], axis = 1).sample(frac = 1.0, random_state = 1).reset_index(drop = True)\n",
    "## print(images_wiki)\n",
    "#\n",
    "## sample(frac = 1.0, random_state = 1) : fraction 100% (uzmi sve slike), random_state = 1 znaci da ih uzimamo random\n",
    "## reset_index(drop = True) poreda ih u ispisu od 0 do 41856 ali random\n",
    "#\n",
    "## ucitaj dir \n",
    "#imdbDir = Path(\"/Users/ninaanic/Tehnicke/6_semestar/ZavRad/main/datasets/imdb_crop\")\n",
    "#filepaths_imdb = pd.Series(list(imdbDir.glob(r'**/*.jpg')), name = 'Filepath').astype(str)\n",
    "#\n",
    "## stvori matricu gdje je jedan stupac naziv slike a 2. broj godina u float-u\n",
    "#ages = []\n",
    "#for img in filepaths_imdb:\n",
    "#    filename = os.path.split(img)[1]\n",
    "#    if (filename == \".DS_Store\"):\n",
    "#        continue    \n",
    "#    try:\n",
    "#        broj_god = int(filename.split('.')[0].split('_')[3]) - int(filename.split('_')[2].split('-')[0])\n",
    "#        ages.append(np.array(broj_god))\n",
    "#        \n",
    "#    except Exception as e:\n",
    "#        pass\n",
    "#\n",
    "#ages = pd.Series(np.array(ages, dtype = np.float64) , name = 'Age')  # One-dimensional ndarray with axis labels ('Age')\n",
    "#images_imdb = pd.concat([filepaths_imdb, ages], axis = 1).sample(frac = 1.0, random_state = 1).reset_index(drop = True)\n",
    "## print(images_imdb)\n",
    "#\n",
    "## sample(frac = 1.0, random_state = 1) : fraction 100% (uzmi sve slike), random_state = 1 znaci da ih uzimamo random\n",
    "## reset_index(drop = True) poreda ih u ispisu od 0 do 41856 ali random\n",
    "#\n",
    "#images = pd.DataFrame(images_imdb.append(images_wiki, ignore_index = True),columns=['Filepath', 'Age'])\n",
    "#print(images)\n",
    "#\n",
    "#\n",
    "## todo: prilagodit jer ValueError: could not broadcast input array from shape (224,224,3) into shape (224,224)\n",
    "## napravimo 2 liste, 1 za trening 2. za test i u njih na random stavljamo slike\n",
    "#X = images['Filepath']\n",
    "#y = images['Age']\n",
    "#\n",
    "#y = y.fillna(0) # remove Nan\n",
    "#\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle = True)\n",
    "#\n",
    "#train_images = []\n",
    "#test_images = []\n",
    "#\n",
    "#for row in X_train:\n",
    "#    image = Image.open(row)\n",
    "#    image = image.resize((224, 224))   # Resize the image\n",
    "#    data = np.asarray(image)\n",
    "#    train_images.append(data)\n",
    "#    \n",
    "#for row in X_test:\n",
    "#    image = Image.open(row)\n",
    "#    image = image.resize((224, 224))  # Resize the image\n",
    "#    data = np.asarray(image)\n",
    "#    test_images.append(data)\n",
    "#    \n",
    "#train_images = np.asarray(train_images)\n",
    "#test_images = np.asarray(test_images)\n",
    "#\n",
    "#print('Train images shape {}'.format(train_images.shape))\n",
    "#print('Test images shape {}'.format(test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95a5fd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTKFaces set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743cd901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape (21337, 200, 200, 3)\n",
      "Test images shape (2371, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "utkDir = Path(\"/Users/ninaanic/Tehnicke/6_semestar/ZavRad/main/datasets/UTKFace\")\n",
    "filepaths_utk = pd.Series(list(utkDir.glob(r'*.jpg')), name = 'Filepath').astype(str)\n",
    "#print(filepaths)\n",
    "\n",
    "ages = []\n",
    "for img in filepaths_utk:\n",
    "    filename = os.path.split(img)[1]\n",
    "    if (filename == \".DS_Store\"):\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        broj_god = int(filename.split('.')[0].split('_')[0])\n",
    "        ages.append(np.array(broj_god))\n",
    "        \n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "ages = pd.Series(np.array(ages, dtype = np.int64) , name = 'Age')  # One-dimensional ndarray with axis labels ('Age')\n",
    "images_utk = pd.concat([filepaths_utk, ages], axis = 1).sample(frac = 1.0, random_state = 1).reset_index(drop = True)\n",
    "#print(images_utk)\n",
    "\n",
    "X = images_utk['Filepath']\n",
    "y = images_utk['Age']\n",
    "\n",
    "y = y.fillna(0) # remove Nan\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle = True)\n",
    "\n",
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "for row in X_train:\n",
    "    image = Image.open(row)\n",
    "    data = np.asarray(image)\n",
    "    train_images.append(data)\n",
    "    \n",
    "for row in X_test:\n",
    "    image = Image.open(row)\n",
    "    data = np.asarray(image)\n",
    "    test_images.append(data)\n",
    "    \n",
    "train_images = np.asarray(train_images)\n",
    "test_images = np.asarray(test_images)\n",
    "\n",
    "print('Train images shape {}'.format(train_images.shape))\n",
    "print('Test images shape {}'.format(test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ec52ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 49, 49, 96)        14208     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " layer_normalization (LayerN  (None, 24, 24, 96)       192       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer_normalization_1 (Laye  (None, 12, 12, 256)      512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer_normalization_2 (Laye  (None, 6, 6, 256)        512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 117)               60021     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,261,941\n",
      "Trainable params: 6,261,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "667/667 [==============================] - 263s 393ms/step - loss: 4.1991 - accuracy: 0.0874 - val_loss: 4.0755 - val_accuracy: 0.0894\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 262s 392ms/step - loss: 4.0788 - accuracy: 0.0930 - val_loss: 4.0733 - val_accuracy: 0.0894\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 681s 1s/step - loss: 4.0784 - accuracy: 0.0930 - val_loss: 4.0750 - val_accuracy: 0.0894\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 505s 758ms/step - loss: 4.0781 - accuracy: 0.0930 - val_loss: 4.0732 - val_accuracy: 0.0894\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 254s 381ms/step - loss: 4.0760 - accuracy: 0.0930 - val_loss: 4.0695 - val_accuracy: 0.0894\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 288s 431ms/step - loss: 4.0775 - accuracy: 0.0930 - val_loss: 4.0711 - val_accuracy: 0.0894\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 300s 450ms/step - loss: 4.0765 - accuracy: 0.0930 - val_loss: 4.0706 - val_accuracy: 0.0894\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 513s 769ms/step - loss: 4.0756 - accuracy: 0.0930 - val_loss: 4.0701 - val_accuracy: 0.0894\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 269s 404ms/step - loss: 4.0746 - accuracy: 0.0930 - val_loss: 4.0712 - val_accuracy: 0.0894\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 291s 437ms/step - loss: 4.0749 - accuracy: 0.0930 - val_loss: 4.0699 - val_accuracy: 0.0894\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 293s 439ms/step - loss: 4.0745 - accuracy: 0.0930 - val_loss: 4.0699 - val_accuracy: 0.0894\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 306s 459ms/step - loss: 4.0748 - accuracy: 0.0930 - val_loss: 4.0688 - val_accuracy: 0.0894\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 309s 463ms/step - loss: 4.0741 - accuracy: 0.0930 - val_loss: 4.0715 - val_accuracy: 0.0894\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 303s 454ms/step - loss: 4.0755 - accuracy: 0.0930 - val_loss: 4.0695 - val_accuracy: 0.0894\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 272s 408ms/step - loss: 4.0732 - accuracy: 0.0930 - val_loss: 4.0700 - val_accuracy: 0.0894\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 272s 407ms/step - loss: 4.0740 - accuracy: 0.0930 - val_loss: 4.0680 - val_accuracy: 0.0894\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 274s 410ms/step - loss: 4.0733 - accuracy: 0.0930 - val_loss: 4.0688 - val_accuracy: 0.0894\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 277s 416ms/step - loss: 4.0730 - accuracy: 0.0930 - val_loss: 4.0663 - val_accuracy: 0.0894\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 277s 415ms/step - loss: 4.0732 - accuracy: 0.0930 - val_loss: 4.0702 - val_accuracy: 0.0894\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 278s 417ms/step - loss: 4.0724 - accuracy: 0.0930 - val_loss: 4.0695 - val_accuracy: 0.0894\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 280s 420ms/step - loss: 4.0727 - accuracy: 0.0930 - val_loss: 4.0695 - val_accuracy: 0.0894\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 279s 418ms/step - loss: 4.0723 - accuracy: 0.0930 - val_loss: 4.0687 - val_accuracy: 0.0894\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 281s 421ms/step - loss: 4.0727 - accuracy: 0.0930 - val_loss: 4.0700 - val_accuracy: 0.0894\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 277s 415ms/step - loss: 4.0730 - accuracy: 0.0930 - val_loss: 4.0687 - val_accuracy: 0.0894\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 278s 417ms/step - loss: 4.0718 - accuracy: 0.0930 - val_loss: 4.0700 - val_accuracy: 0.0894\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 279s 419ms/step - loss: 4.0721 - accuracy: 0.0930 - val_loss: 4.0693 - val_accuracy: 0.0894\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 278s 417ms/step - loss: 4.0718 - accuracy: 0.0930 - val_loss: 4.0683 - val_accuracy: 0.0894\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 282s 423ms/step - loss: 4.0714 - accuracy: 0.0930 - val_loss: 4.0677 - val_accuracy: 0.0894\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 280s 420ms/step - loss: 4.0721 - accuracy: 0.0930 - val_loss: 4.0693 - val_accuracy: 0.0894\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 277s 416ms/step - loss: 4.0721 - accuracy: 0.0930 - val_loss: 4.0682 - val_accuracy: 0.0894\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 275s 413ms/step - loss: 4.0723 - accuracy: 0.0930 - val_loss: 4.0673 - val_accuracy: 0.0894\n",
      "\n",
      "   done   \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(200, 200, 3), filters=96, kernel_size=(7, 7), strides=4, padding='valid', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=117, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) # Callback for early stopping\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "history = model.fit(train_images, y_train, batch_size=32, epochs=50, validation_data=(test_images, y_test), callbacks=[callback])\n",
    "\n",
    "print()\n",
    "print(\"   done   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59a6fe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 - 9s - loss: 4.0673 - accuracy: 0.0894 - 9s/epoch - 117ms/step\n",
      "Test acc: 0.08941374719142914\n",
      "Test loss: 4.067340850830078\n"
     ]
    }
   ],
   "source": [
    "# step 4.7: resultati (usporedujemo predictanu i stvarnu godinu osobe sa slike)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, y_test, verbose=2)\n",
    "print('Test acc:', test_acc)\n",
    "print('Test loss:', test_loss) #Unlike accuracy, a loss is not a percentage. It is a sum of the errors made for each example in training or validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efa616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
